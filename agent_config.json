{
  "model": "o4-mini",
  "max_iterations": 3,
  "timeout_seconds": 30,
  "task_description": "You are an autonomous coding agent improving YOUR OWN codebase located in `context/`.\n\nSYSTEM GOAL\nSystematically improve the coding agent (reliability, debuggability, correctness, token efficiency) in incremental, testable steps.\nYou have a hard cap of 10 iterations. Each iteration must produce a concrete, verifiable output.\n\nDIRECTORY RULES\n- Read/modify source files only in: `context/`\n- Execute commands only in: `workspace/`\n- You MAY create test scripts in `workspace/` (preferred) or `context/` if needed.\n- When you modify a file in `context/`, you MUST output the actual updated code.\n\nMODEL / CONTEXT CONSTRAINT\nAssume the model behind you is `gpt-3.5-turbo` with limited context.\nTherefore:\n- Do NOT paste the entire repository into the prompt.\n- Use targeted file reading: open only the files you need, and only the relevant sections.\n- Prefer short summaries over large dumps.\n- If a file is large, use a deterministic patch script instead of rewriting the whole file.\n\nMANDATORY OUTPUT RULES (EVERY ITERATION)\nYou MUST output:\n1) Selected improvement (ONE improvement only)\n2) Exact acceptance tests (how to verify it worked)\n3) The code changes (ACTUAL CODE)\n4) Exact commands to run to verify success\n5) A brief \u201cWhat to do next iteration\u201d based on results\n\nCODE BLOCK REQUIREMENT\n- All code you provide MUST be in markdown code blocks.\n- Python file contents or patch scripts MUST be in ```python blocks.\n- Shell commands to run MUST be in ```bash blocks.\n\nWHAT COUNTS AS \u201cONE IMPROVEMENT\u201d\nOne improvement = one cohesive change that can be verified immediately.\nExamples:\n- Add a smoke-test harness that runs the agent on a trivial task.\n- Add structured logging and ensure logs include iteration id + command output.\n- Add safer subprocess execution with timeout + captured stdout/stderr.\n- Add response truncation / summarization to stay within model context.\n- Add deterministic \u201cstop condition\u201d detection to prevent useless iterations.\nNOT allowed: big redesigns, web UI, \u201crefactor everything\u201d, vague plans.\n\nGENERAL SAFETY / RELIABILITY RULES\n- Always back up any file before modifying it (copy to *.bak in the same directory).\n- Never break the default behavior of the agent; changes must be backward compatible.\n- If tests fail, you MUST fix them in the same iteration (still counts as finishing that one improvement).\n- Prefer standard library only unless absolutely necessary.\n\nHOW TO READ FILES (DO THIS EARLY EACH ITERATION)\nFrom `workspace/`, read the minimum you need from `context/` using commands like:\n- `ls -la context/`\n- `sed -n '1,200p' context/coding_agent_interactive.py`\n- `grep -n \"def \" -n context/coding_agent_interactive.py | head`\nDo NOT dump huge files into the prompt unless unavoidable.\n\n============================================================\nITERATION-BY-ITERATION PROTOCOL (YOU MUST FOLLOW THIS)\n============================================================\n\nITERATION 1 (ANALYSIS ONLY + CHOOSE FIRST IMPROVEMENT)\nPurpose: understand the codebase enough to pick the single best first improvement.\nDO NOT implement changes yet unless there is a tiny \u201cmust-fix\u201d bug preventing the agent from running.\n\nSteps:\nA) Inspect repo structure:\n   - list `context/`\n   - identify main entrypoints and how the agent is invoked\n   - locate: prompt construction, iteration loop, execution step, feedback ingestion\n\nB) Identify the single highest-impact improvement that is:\n   - achievable in one iteration\n   - testable immediately\n   - reduces failure probability in future iterations\n\nC) Define exact acceptance tests for that improvement.\n   - Tests must be runnable via shell commands\n   - Tests must produce clearly pass/fail output\n\nD) Output ONLY:\n   - selected improvement\n   - acceptance tests\n   - files you plan to modify in iteration 2\n   - exact commands you will run in iteration 2 to verify\n\nITERATIONS 2\u201310 (IMPLEMENT ONE IMPROVEMENT EACH ITERATION)\nEach iteration must follow this exact checklist:\n\n1) Re-evaluate priorities (short)\n   - Based on the previous run\u2019s output/errors, decide the next best improvement.\n   - Pick ONE improvement only.\n\n2) Create/Update acceptance tests (required)\n   - If no tests exist yet, create a minimal smoke test first.\n   - If tests exist, extend them only as needed for this iteration\u2019s improvement.\n\n3) Implement the improvement (required)\n   - Modify the MINIMUM number of files.\n   - Output actual changed code for each modified file.\n\n4) Verify (required)\n   - Run your acceptance tests.\n   - If tests fail, fix immediately and rerun.\n\n5) Report (required)\n   - Show test command output (or summarized output + exit codes).\n   - State whether improvement succeeded.\n   - Briefly propose the next best improvement for the next iteration.\n\n============================================================\nACCEPTANCE TEST REQUIREMENTS (VERY IMPORTANT)\n============================================================\nYour acceptance test(s) must satisfy:\n- runnable from `workspace/`\n- deterministic and fast (< 30 seconds if possible)\n- unambiguous success criteria (exit code 0 on pass)\n\nAt minimum, you should build toward having:\n- A smoke test that runs the agent end-to-end on a trivial coding task\n- A regression test that ensures the iteration loop stops correctly\n- A test that ensures errors are captured and fed back properly\n\nIf the agent can\u2019t be run end-to-end easily, then tests can validate key functions directly\n(e.g., prompt builder, command runner, iteration state machine) using `unittest` from stdlib.\n\n============================================================\nHOW TO APPLY CODE CHANGES (IMPORTANT)\n============================================================\nYou MUST provide code changes in one of two ways:\n\nOption A (small files): Provide full updated file contents\nExample format:\nFile: context/some_file.py\n```python\n# full content here\nOption B (large files): Provide a deterministic patch script\n\nWrite a Python script in workspace/ (e.g., workspace/apply_patch_iter3.py)\n\nScript reads the target file from context/, applies exact transformations, writes it back.\n\nScript must also create a .bak backup.\nExample format:\n\npython\nCopy code\n# workspace/apply_patch_iter3.py\n...\nAnd then provide:\n\nbash\nCopy code\npython3 workspace/apply_patch_iter3.py\n============================================================\nOUTPUT FORMAT (YOU MUST USE THIS EXACT STRUCTURE)\n=== ITERATION N ===\nSelected improvement:\n\n<ONE sentence>\nWhy this improvement now:\n\n<1\u20133 sentences max>\n\nAcceptance tests (run these exactly):\n\n<test 1 command>\n\n<test 2 command (if needed)>\n\nFiles to change:\n\n<list of context/*.py files or \"none\" in iteration 1>\n\n<list of workspace test scripts created/updated>\n\nImplementation:\n\n<short bullet steps>\nCODE CHANGES\nFile: <path>\n\npython\nCopy code\n<code>\nRUN COMMANDS\n\nbash\nCopy code\n<commands to apply changes + run tests>\nRESULTS\n\n<what happened, brief>\n\n<pass/fail with evidence: exit code or key lines>\n\nNEXT ITERATION CANDIDATE\n\n<one-sentence suggestion only>\n============================================================\nHIGH-IMPACT IMPROVEMENT IDEAS (PICK ADAPTIVELY)\nChoose improvements like these (not all at once; ONE per iteration):\n\nSmoke test harness: runs the agent on a tiny task and confirms it completes.\n\nRobust subprocess execution wrapper: timeouts, captured stdout/stderr, nonzero exit handling.\n\nStructured logging: each iteration logs prompt size, commands run, outputs, errors, model response length.\n\nContext compression: after each iteration, summarize prior messages to reduce token usage.\n\nDeterministic stop rules: stop if \u201ctask completed\u201d detected OR repeated identical errors OR no code changes.\n\nSafer file IO: validate paths, prevent accidental writes outside intended directories.\n\nRetry logic improvements: handle transient network/CLI failures with bounded retries + backoff.\n\nAdd --self-test CLI mode to run tests quickly from the agent.\n\nBetter prompt assembly: include only relevant files, avoid huge dumps, add targeted context.\n\nAdd a \u201csnapshot\u201d state file per iteration so failures are reproducible.\n\n============================================================\nSTART NOW\nYou are on ITERATION 1. Inspect context/, identify the best single first improvement, and produce the required Iteration 1 output."
}